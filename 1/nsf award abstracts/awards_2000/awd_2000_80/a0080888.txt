Title       : Practical Reasoning in Autonomous Agents
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : June 7,  2002       
File        : a0080888

Award Number: 0080888
Award Instr.: Continuing grant                             
Prgm Manager: William Bainbridge                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2000  
Expires     : August 31,  2003     (Estimated)
Expected
Total Amt.  : $331169             (Estimated)
Investigator: John L. Pollock pollock@arizona.edu  (Principal Investigator current)
Sponsor     : U of Arizona
	      601 Administration Building
	      Tucson, AZ  85721    602/621-2211

NSF Program : 6856      KNOWLEDGE & COGNITIVE SYSTEMS
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
                  AI is approaching the point where it will be possible to build autonomous
              robotic agents capable of performing human-like tasks without direct human
              control.  Such autonomous agents must be able to plan their activities in the
              face of incomplete knowledge of their environment.  This project aims at
              understanding how such planning works and building implemented systems that
              accomplish it.  Specifically, this investigation is aimed at the construction
              of an artificial rational agent capable of engaging in decision-theoretic
              planning in environments of realistic complexity and unpredictability. The
              design of a system to do automated planning is one of the traditional goals of
              artificial intelligence research, and some highly successful planning systems
              have been constructed for use in narrowly constrained environment;  however,
              these systems presuppose that the planner knows everything it needs to know
              when it is first presented with the planning problem, and most of them further
              require complete knowledge of all relevant aspects of the agent's environment
              and knowledge of precisely what will result from performing any relevant act in
              any circumstance the planner will encounter.  While such assumptions might be
              satisfied by an industrial robot operating in a constrained environment, human
              beings plan without satisfying any of these conditions.  In particular,
              planning problems often drives the search for new knowledge rather than
              presupposing that the planning agent knows everything it needs to know from the
              beginning.  And human beings do not assume that they can predict with certainty
              what will happen when they perform any available action under any conceivable
              circumstances.  In constructing and evaluating plans, people take account of
              the varying probabilities of different consequences of actions, and they assign
              values and costs to those consequences before deciding whether to adopt a
              proposed plan.   In other words, they plan decision-theoretically.   The
              objective of this project is to understand how decision-theoretic planning is
              possible in an agent operating in an uncooperative and only partially
              predictable environment, and then to build an artificial agent whose planning
              capabilities more closely approximate those of human beings.  This should
              illuminate some of the structure of rational cognition in both artificial
              agents and human agents.
