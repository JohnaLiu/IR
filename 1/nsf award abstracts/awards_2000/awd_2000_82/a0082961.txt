Title       : ITR: Environment Management for Hybrid User Interfaces
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 2,  2002       
File        : a0082961

Award Number: 0082961
Award Instr.: Continuing grant                             
Prgm Manager: William Bainbridge                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2000  
Expires     : August 31,  2003     (Estimated)
Expected
Total Amt.  : $450000             (Estimated)
Investigator: Steven K. Feiner feiner@cs.columbia.edu  (Principal Investigator current)
Sponsor     : Columbia University
	      1210 Amsterdam Avenue; MC 2205
	      New York, NY  10027    212/854-6851

NSF Program : 1640      INFORMATION TECHNOLOGY RESEARC
Fld Applictn: 0104000   Information Systems                     
Program Ref : 1654,1660,9218,HPCC,
Abstract    :
              This is the first year funding of a three-year continuing award. Hybrid user
              interfaces combine together multiple displays and interaction devices to
              benefit from the advantages of each.  For example, a hybrid user interface
              could be constructed in which multiple users view one or more common displays,
              such as a wall-mounted data visualization and a desk-top virtual workbench 3D
              model.  At the same time, each user might see complementary private material,
              customized to her own information needs, and overlaid on and registered with
              the common displays---an augmented reality that is presented on personal,
              tracked, hand-held or head-worn see-through displays.This project addresses
              environment management, the task of managing large numbers of virtual objects
              on large numbers of displays in hybrid user interfaces. More complex than the
              tasks involved in current window management, environment management will be
              especially challenging if it is to address the needs of future mobile,
              collaborating users, whose proximity to other users, displays, and interaction
              devices may change rapidly and unpredictably as users move about. This work
              explores an alternative to direct manipulation approaches, in which
              knowledge-based environment management tools take over many  low-level tasks to
              avoid overwhelming the user.  The goal is to increase a user's effectiveness by
              making it possible for her to exert higher-level control over the layout and
              contents of her personal and shared work environment. This project will develop
              the underlying concepts for hybrid user interfaces and effective environment
              management facilities, and will design, demonstrate, and test research
              prototypes that embody these concepts.  Special emphasis is placed on issues
              raised by collaborative, 3D augmented environments that exploit a wide range of
              displays (held, worn, and stationary), including head-tracked see-through
              displays that create augmented realities, in which virtual objects coexist in
              the same surrounding space as users and other physical objects. User interface
              design approaches that can promote shorter task performance time, lower error
              rate, or greater user satisfaction, will be vital for improving our ability to
              interact with information and with each other in the nontraditional world of
              collaborative mobile computing.
