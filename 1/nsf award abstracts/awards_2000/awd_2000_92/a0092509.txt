Title       : Trends And Empirical Econometric Limits
Type        : Award
NSF Org     : SES 
Latest
Amendment
Date        : March 3,  2003      
File        : a0092509

Award Number: 0092509
Award Instr.: Continuing grant                             
Prgm Manager: Kwabena Gyimah-Brempong                 
	      SES  DIVN OF SOCIAL AND ECONOMIC SCIENCES    
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : May 1,  2001        
Expires     : April 30,  2004      (Estimated)
Expected
Total Amt.  : $226927             (Estimated)
Investigator: Peter C. Phillips peter.phillips@yale.edu  (Principal Investigator current)
Sponsor     : Yale University
	      P.O. Box 208337
	      New Haven, CT  065208337    203/432-2460

NSF Program : 1320      ECONOMICS
Fld Applictn: 
Program Ref : 0000,OTHR,
Abstract    :
              

An important issue that bears on all practical economic analysis is the
              extent to which
we can expect to understand economic phenomena by the process
              of developing a theory,
taking observations and fitting a model. An especially
              relevant question in practice is
whether there are limits on how well we can
              predict future observations using empirical
models that are obtained by such
              processes. Finding quantitative expression for these
limits is the main
              subject of the project.
A primary limitation on empirical knowledge is that
              the true model for any given data
is unknown and, in all practical cases,
              unknowable. This is because even if the formulated
model were correct it would
              still depend on parameters that need to be estimated from
data. Often, the
              data is scarce relative to the number of parameters that need to be
estimated,
              and this is especially so in models that have some functional
              representation
that necessitates the use of nonparametric or semiparametric
              methods. In such situations
one might expect that the empirical limitations on
              modeling are greater than in finite
parameter models. Using reasoning that was
              pioneered by Jorma Rissanen in 1987, the
author has shown in collaborative
              work with Werner Ploberger in 1999 that there is a
quantitative bound on how
              close an empirical model can get (in terms of its log likelihood
ratio) to the
              true model. This bound depends on the data itself as well as the model that
is
              being used. A discovery that seems important in applications to economic data
              is that
the magnitude of the bound depends on the presence and nature of
              trends in the data.
In particular, the achievable distance is greater for
              trending data than when the data are
stationary. This result gives
              quantitative expresssion to the intuitively appealing notion
that trending
              data is harder to predict than data that does not trend. The project
              develops
and extends limitation results of this type to models where there are
              local and gross
errors of specification, to nonparametric situations where the
              dimension of the parameter
space is infinite or where it may grow with the
              sample size, that is, in situations where
modeling becomes more ambitious as
              more data becomes available. The project also seeks
to develop explicit
              representations of the forecast error divergence so that the limits
              on
empirical forecasting capability are quantifed. The intent of this project
              is to develop
the theory to a stage where the limits will be useful to
              empirical researchers, especially in
terms of the implementation of model
              determination criteria that are designed to achieve
the empirical bounds.
In
              subsidiary wings of research that relate to this main theme, the project
              studies
more explicit issues of trend regression, where the order of magnitude
              of the trend is
not specifed but has to be estimated, where there is long
              memory in the data which is
possibly nonstationary and the memory parameter
              must be estimated semiparametrically,
and where there is nonstationary
              explanatory data but a limited dependent variable.
The latter study is
              relevant to market intervention policy by the Federal Reserve and
Treasury.
              Thus, monetary policy intervention is a binary decision (intervene or not),
              yet
the explanatory variables that determine it involve a host of economic
              data, much of which
has nonstationary features, like the growth
              characteristics of industrial production and the
random wandering behavior of
              stock prices. We seek to learn how various characteristics in
the explanatory
              data translate into the probability law for the binary variable and,
              hence,
market intervention. Can these probability laws explain, for instance,
              the tendency of
market intervention to lapse into long periods of little
              intervention broken by periods of
regular intervention?
