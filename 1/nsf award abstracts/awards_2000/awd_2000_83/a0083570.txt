Title       : Instrumentation: Free-Viewing Eyetracker for Studies of Visuo-Spatial Cognition
               and Psycholinguistics
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : November 12,  2002  
File        : a0083570

Award Number: 0083570
Award Instr.: Standard Grant                               
Prgm Manager: John E. Yellen                          
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : August 15,  2000    
Expires     : July 31,  2003       (Estimated)
Expected
Total Amt.  : $51314              (Estimated)
Investigator: Fernanda Ferreira fernanda@eyelab.msu.edu  (Principal Investigator current)
              John M. Henderson  (Co-Principal Investigator current)
Sponsor     : Michigan State University
	      
	      East Lansing, MI  48824    517/355-1855

NSF Program : 1327      SBE INSTRUMENTATION
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 0000,OTHR,
Abstract    :
              Ferreira
0083570

The grant provides funds to allow the investigators to
              obtain significant instrumentation for cognitive / behavioral research. The
              requested-funds wo6/ld be used to purchase a free-viewing, mobile eye movement
              monitoring system, along with a computer workstation and a monitor for
              displaying some stimuli (in other cases, stimuli will be real,
              three-dimensional objects and scenes). The mobile eyetracker allows the viewer
              to examine real-world scenes or visual displays of scenes while making normal,
              natural head and body movements. Indeed, the system allows researchers to
              obtain precise information about where a person is looking as he or she moves
              through or manipulates objects in a natural environment. The instrumentation
              would be used for a variety of studies in cognitive and behavioral sciences.
              These include: (1) Research to examine how comprehenders quickly obtain
              interpretations for spoken sentences. No other existing methodology allows
              researchers to measure moment-by-moment processing for aurally presented
              sentences. (2) Research to study how real-world scenes are represented, and how
              representations of objects and scenes are generated dynamically over time in
              the context of meaningful actions. (3) Investigations of how humans are able to
              navigate novel and familiar environments, focusing particularly on eye movement
              patterns (e.g., what objects are used as guideposts and landmarks). (4) Studies
              of human-computer interaction, including the representation of objects and
              navigation through "virtual reality" environments. The free-viewing eyetracker
              would complement the Principal Investigators' existing laboratory facilities
              and greatly enhance the ability to train undergraduate and graduate students in
              sophisticated methodologies for studying complex behavior in intelligent
              systems.

