Title       : Context and Learning in Visual Processing
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : March 20,  2001     
File        : a0096178

Award Number: 0096178
Award Instr.: Continuing grant                             
Prgm Manager: Joseph L. Young                         
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : September 1,  1999  
Expires     : January 31,  2002    (Estimated)
Expected
Total Amt.  : $224859             (Estimated)
Investigator: Marvin M. Chun marvin.chun@vanderbilt.edu  (Principal Investigator current)
Sponsor     : Vanderbilt University
	      512 Kirkland Hall
	      Nashville, TN  37240    615/322-2631

NSF Program : 1180      HUMAN COGNITION & PERCEPTION
Fld Applictn: 
Program Ref : 0000,8888,OTHR,
Abstract    :
              One of the most fundamental problems in visual perception and cognition
              is
information overload.  Given limited processing capacity, there's
              simply
too much perceptual information competing for the control of thought
              and
action.  Hence, observers must use selective attention to
              rapidly
prioritize which aspects of a complex scene are most relevant to
              behavior.
For instance, drivers must be able to efficiently locate and
              identify
traffic signals and stop signs amidst a dizzying mosaic of
              visual
information. People are highly adept at this, while artificial systems
              are
not.  This is because human observers employ powerful top-down
              knowledge
to guide their perceptual interactions with the complex
              environment.
Top-down knowledge is useful because the visual world is
              highly
structured.  For example, spatial layout of landmarks are
              relatively
stable, certain objects tend to covary with others (toasters with
              ovens,
desks with lamps, etc.), and even moving objects such as cars tend to
              move
around in systematic, predictable ways.   Sensitivity to this
              structure,
presented to observers in the form of global visual context,
              provides
useful constraints on visual processing.  Importantly, this
              contextual
information must be "learned" by perceivers.  Thus, the goal of
              this
project is to establish the importance of contextual information
              and
learning mechanisms in object recognition and visual search.  The
              first
set of studies examines how visual contexts are defined, how
              contextual
information is learned and represented, and how learned information
              is
applied to new instances.  The second set of studies examines how
              temporal
context information influences visual processing, and whether
              learning
affects other visual processes such as the ability to segregate
              figure
from ground. Successful completion of these studies will provide
              important
insights into top-down processing and learning mechanisms in human
              vision.
This understanding will be applicable to the design of more
              effective
artificial systems, enabling these to benefit from perceptual
              experience
as people do.





