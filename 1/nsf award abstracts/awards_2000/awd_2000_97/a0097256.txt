Title       : Customized Spatial Sound for Human/Computer Interaction
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : February 25,  2003  
File        : a0097256

Award Number: 0097256
Award Instr.: Continuing grant                             
Prgm Manager: Mary P. Harper                          
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 15,  2001 
Expires     : August 31,  2004     (Estimated)
Expected
Total Amt.  : $731400             (Estimated)
Investigator: V. Ralph Algazi algazi@ece.ucdavis.edu  (Principal Investigator current)
              Richard O. Duda  (Co-Principal Investigator current)
Sponsor     : U of Cal Davis
	      OVCR/Sponsored Programs
	      Davis, CA  956168671    530/752-2075

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
Program Ref : 6845,9218,HPCC,
Abstract    :
              Current systems that generate spatial sound for computer-based
applications
              employ Head-Related Transfer functions (HRTFs) and
simple models of room
              reflections to provide the acoustic localization
cues.  However, the abilities
              of these systems to generate well-controlled
spatial sound streams are quite
              limited.  Although it is possible to position
virtual sound sources to the
              left or right rather accurately, front/back 
confusion is common, localization
              in elevation is problematic, and localization
in range is unreliable.

This
              proposal describes a comprehensive program of research directed at solving
the
              major problems that are the cause of these limitations.   These problems
are
              identified as (a) a mismatch between the HRTF used by the system and
the
              listener's actual HRTF, (b) a failure to provide the correct dynamic cues
that
              occur when the listener moves relative to the source, (c) a mismatch between
              
synthesized room reflections and the listener's experience or expectations,
              and
(d) a failure to render the correct spectral cues for familiar
              sounds,
such as human speech.
