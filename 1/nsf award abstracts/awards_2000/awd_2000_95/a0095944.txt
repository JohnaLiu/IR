Title       : Haptic Interfaces for Spatial Learning
Type        : Award
NSF Org     : HRD 
Latest
Amendment
Date        : January 24,  2003   
File        : a0095944

Award Number: 0095944
Award Instr.: Continuing grant                             
Prgm Manager: Arthur Karshmer                         
	      HRD  DIVISION OF HUMAN RESOURCE DEVELOPMENT  
	      EHR  DIRECT FOR EDUCATION AND HUMAN RESOURCES
Start Date  : April 15,  2001     
Expires     : March 31,  2004      (Estimated)
Expected
Total Amt.  : $449864             (Estimated)
Investigator: Lucy Y. Pao pao@colorado.edu  (Principal Investigator current)
              Dale A. Lawrence  (Co-Principal Investigator current)
              Howard Kramer  (Co-Principal Investigator current)
Sponsor     : U of Colorado Boulder
	      3100 Marine Street, Room 481
	      Boulder, CO  803090572    303/492-6221

NSF Program : 1545      EHR ACT IN SEM FOR PER WITH DI
Fld Applictn: 
Program Ref : 9178,SMET,
Abstract    :
              Proposal # HRD-0095944
Institution: University of Colorado at
              Boulder
Principal Investigators: Lucy Y. Pao, Dale A. Lawrence, and
Howard
              Kramer 
Title: "Haptic Interfaces for Spatial Learning"

ABSTRACT

This
              project will explore the use of haptic (touch) interfaces, in concert with
              conventional visual and audio interfaces, to enhance communication and learning
              of spatial concepts in science and engineering.  Graphical means of expressing
              spatial concepts provide the most clear and concrete representation of spatial
              ideas, but are often the most difficult for people to use.  In contrast to
              existing approaches that use only vision, the project will seek non-visual
              means of expressing and communicating spatial ideas and data.  The approach
              also differs from recent attempts to reproduce 2D visual graphs or pictures as
              2D haptic or tactile artifacts for the visually impaired.  Such approaches
              depend on projections of 3D objects onto viewing planes, a technique that is
              only marginally accessible to blind people.  

Technology exists that can
              enable people to draw effectively in 3D without depending on vision or
              vision-like projections of the 3D object or idea.  The project will explore the
              integration of a 6 degree of freedom (DOF) haptic interface with new software
              tools that produce a variety of direct 3D drawing capabilities, including the
              capability to instantly review and correct the concept as it is created. 
              Investigators will explore the benefits of non-visual (haptic and audio)
              feedback for drawing.  We believe non-visual interaction with drawing tools can
              make graphical representations of spatial constructs, relationships, and ideas
              much easier to generate and share, promoting clearer discourse in fields that
              depend on spatial concepts.  The ability to create precise 3D drawings would
              provide a mode of communication for visually impaired people opening new
              opportunities in fields that require an ability to communicate using spatial
              representations.  

The technology to be developed and test consists of a
              desktop workstation that provides capability for visual, audio, and haptic
              interaction with computer-generated spatial constructs.  The tools will consist
              of software programs that allow users to easily draw in 3-dimensions with
              visual, haptic, and audio feedback.  A suite of rendering/drawing modes will
              also be developed to enable users to create and interpret 3-dimensional objects
              or drawings. 

The existing visual/haptic interface facility at the
              University of Colorado will be augmented with audio capabilities similar to
              those currently used in the University of Colorado Assistive Technology Lab. 
              This augmented workstation will be used as a testbed during years 1 and 2 of
              the project, where work will focus on the development and testing of particular
              modes of drawing and rendering spatial objects and data, and of particular
              pedagogic approaches to learning spatial concepts.  The resulting rendering
              modes will be evaluated by students with learning and/or visual impairments as
              well as non-impaired students who are interested in science and engineering. 
              


