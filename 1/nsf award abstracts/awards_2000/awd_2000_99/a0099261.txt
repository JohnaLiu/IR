Title       : Transcending The Digital Divide
Type        : Award
NSF Org     : HRD 
Latest
Amendment
Date        : January 27,  2003   
File        : a0099261

Award Number: 0099261
Award Instr.: Continuing grant                             
Prgm Manager: Arthur Karshmer                         
	      HRD  DIVISION OF HUMAN RESOURCE DEVELOPMENT  
	      EHR  DIRECT FOR EDUCATION AND HUMAN RESOURCES
Start Date  : January 15,  2001   
Expires     : December 31,  2003   (Estimated)
Expected
Total Amt.  : $448390             (Estimated)
Investigator: Reginald G. Golledge golledge@geog.ucsb.edu  (Principal Investigator current)
Sponsor     : U of Cal Santa Barbara
	      Office of Research
	      Santa Barbara, CA  93106    805/893-4188

NSF Program : 1545      EHR ACT IN SEM FOR PER WITH DI
Fld Applictn: 
Program Ref : 9177,SMET,
Abstract    :
              Proposal # HRD-00-99261
Institution: UC Santa Barbara
Principal Investigator:
              Reginald Golledge
Title: "Transcending the Digital Divide"

ABSTRACT

The
              purpose of this research is to develop, evaluate, and disseminate a non-visual
              interface for accessing digital information.  The aim is to investigate the
              perceptual and cognitive problems that blind people face when trying to
              interpret information provided in a multimodal manner.  The project also plans
              to provide touch sensitive and sound based network interface and navigation
              devices that incorporate cognitive wayfinding heuristics.  Haptic (force
              feedback) interfaces will be provided for exploring web pages that consist of
              map, graphic, iconic or image products.  Sound identifiers for on-screen
              windowed, map, and image information will also be provided.  These tasks will
              contribute to transcending the Digital Divide that increasingly separates blind
              or vision impaired people from the growing information-based workplace. 
              

Recent research at UCSB has begun to explore how individuals identify
              features presented through sound and touch.  Other research (e.g.  O'Modhrrain
              and Gillespie, 1998; McKinley and Scott, 1998) have used haptics to explore
              screen objects such as windows, pulldown menus, buttons, and sliders; but map,
              graphic and other  cartographic representations have not been explored.  In
              particular, the potential of auditory maps of on-screen phenomena (e.g.  as
              would be important in GIS applications) has barely been examined and few
              examples exist of combining audio and touch principles to build an interface. 
              While imaginative efforts to build non-visual interfaces have been proceeding. 
              there is a yet little empirical evidence that people without sight can use them
              effectively (i.e. develop a true representation of the experienced phenomena). 
              

Experiments will be undertaken to test the ability of vision impaired and
              sighted people from different age groups to use these new interface or features
              such as: (i) the haptic mouse or a touch window tied to auditory communication
              displays; (ii) digitized real sounds to indicate environmental features at
              their mapped locations; (iii) "sound painting" of maps, images, or charts to
              indicate gradients of phenomena like temperature, precipitation, pressure,
              population density and altitude.  Tests will be developed to evaluate (i) the
              minimum resolvable area for the haptic interpretation of scenes; (ii) the
              development of skills for shape tracing in the sound or the force-feedback
              haptic domain, (iii) the possibility of using continuous or discreet sound
              symbols associated with touch sensitive pads to learn hierarchically nested
              screen information (e.g. locations of cities within regions within states
              within nations); (iv) to evaluate how dynamic activities such as scrolling,
              zooming, and searching can be conducted in the haptic or auditory domain, (v)
              to evaluate people's comprehension and ability to explore, comprehend, and make
              inferences about various non-visual interpretations of complex visual displays
              (e.g. maps and diagrams), and (vi) to explore the effectiveness of using a
              haptic mouse with a 2" square motion domain to search a 14" screen (i.e. scale
              effects).  

