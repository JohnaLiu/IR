Title       : New Methods for Maintaining Good Stereoscopic Viewing During Interaction with
               Large-Scale Head-Tracked Displays
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 27,  2001      
File        : a9977325

Award Number: 9977325
Award Instr.: Continuing grant                             
Prgm Manager: Mary P. Harper                          
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 15,  1999    
Expires     : July 31,  2003       (Estimated)
Expected
Total Amt.  : $423481             (Estimated)
Investigator: Larry F. Hodges   (Principal Investigator current)
              Martin W. Ribarsky  (Co-Principal Investigator current)
Sponsor     : GA Tech Res Corp - GIT
	      Office of Sponsored Programs
	      Atlanta, GA  303320420    404/385-0866

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              Virtual reality (VR) aims to perceptually place the user in an artificial world
              through computer-generated sight and sound.  VR thus offers a new
              human-computer interaction paradigm which can improve the user's understanding
              of and interaction with 3D information spaces in diverse applications domains
              such as design, data visualization, training, education, and medicine. 
              Stereoscopic VR systems generate imagery by presenting a separate perspective
              image to each eye.  As a result, the user perceives a single, true 3D image
              that appears to exist in front of and behind the physical display surface. 
              While stereoscopic display is an important and common feature in VR systems,
              further research is needed because stereoscopic viewing raises concerns beyond
              those raised in monoscopic VR systems as the user travels through and
              manipulates the virtual environment.  This is especially true for extended
              virtual environments where the scene contains rendered geometric detail at
              scales covering several orders of magnitude.  In such environments, users need
              to zoom in and out to move between detailed and global views.  This project
              will investigate techniques for maintaining good stereoscopic viewing
              conditions under such conditions.  The PIs will focus on stereoscopic
              Head-Tracked Display systems such as the virtual workbench (as distinguished
              from head-mounted displays in which the display surface is mounted on the
              user's head).  The expected impact of this project will be better understanding
              and implementations of head-tracked displays based on a thorough geometric and
              analytic analysis of false eye separation and head-tracking distortions; new
              and improved techniques for automatic view optics adjustments and automatic
              view position adjustments to maintain good stereoscopic viewing conditions; and
              a systematic study of the compatibility between the above methods and the
              relevant geometric attributes of VR applications.


