Title       : Model and Motion Libraries from Video
Type        : Award
NSF Org     : CCR 
Latest
Amendment
Date        : March 17,  2003     
File        : a9972464

Award Number: 9972464
Award Instr.: Standard Grant                               
Prgm Manager: John Staudhammer                        
	      CCR  DIV OF COMPUTER-COMMUNICATIONS RESEARCH 
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : July 15,  1999      
Expires     : June 30,  2004       (Estimated)
Expected
Total Amt.  : $387000             (Estimated)
Investigator: Jane Wilhelms wilhelms@cse.ucsc.edu  (Principal Investigator former)
Sponsor     : U of Cal Santa Cruz
	      1156 High Street
	      Santa Cruz, CA  950641077    408/429-0111

NSF Program : 2865      GRAPH & SYMB & GEO COMPUTATION
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 9216,HPCC,
Abstract    :
              9972464   Wilhelms, Jane
This project investigates new methods of extracting
              general, three-dimensional human and animal models and their motion from 
              digitized video,  in order to create an accurate and realistic virtual library.
               Realistic, computer-animated humans and animals are important in computer
              graphics and many other fields, including biomechanics, biology, surgical
              planning, sports medicine, engineering, education, training, and ergonomics. 
              Natural human movement simulation is important in the ergonomic design of
              environments such as cars, planes, and work places.  While much work has been
              done in the anthropomorphic study of the range of human body types, less is
              known about the natural range of comfortable motion among individuals in
              specific environments.  Locomotion studies of humans and animals would profit
              from three-dimensional representations that allow quantitative comparisons
              between recorded motion of different individuals and species.  Humans and
              animals lend verisimilitude and interest to any computer-generated scene. 
              Videotape already records massive amounts of information on the free movement
              of humans and many animal species;  what is needed are ways to extract
              quantitative information from these records.  However, generating the realistic
              motion of complex articulated structures is extremely difficult.  Trained
              animators can produce realistic motion using laborious keyframing techniques,
              but results are not useful for scientific study.  Considerable research has
              been done in the last 15 years in attempting to use constraints, physical
              simulation, and higher-level procedural specification to partially automate the
              process with some encouraging but limited results.  Studio motion capture
              techniques can provide exact motion specification for single individuals, at
              considerable cost, but work has just begun on generalizing these results. 
              Computer vision is developing automatic recognition approaches, but at this
              point results are only reliable for simplified cases and environments.  Methods
              of extracting accurate three-dimensional motion from video filmed using a
              single camera in any general environment will provide the necessary general
              tool for turning recorded motion into a quantitatively useful form.  This
              project will bring together several research areas to attack the problem of
              extracting and representing articulated motion.  The process will combine
              parametric, hierarchical, and constraint-based methods from computer graphics,
              physiological insights from biology and biomechanics, and model-based
              image-by-synthesis approaches from computer vision.  The process will be
              partially automated, but user input will provide necessary initial conditions
              and alterations when necessary.
The result will be a library of accurate human
              and animal models accompanied by realistic parameterized, hierarchical motion
              descriptions.  Scientists in other research areas, such as biology,
              biomechanics, anthropology, and vision, both at the University of California,
              Santa Cruz, and elsewhere will be involved.  The virtual library will be made
              available, and software will be modular to facilitate integration with existing
              systems.

