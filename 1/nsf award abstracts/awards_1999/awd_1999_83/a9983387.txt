Title       : Viewing Geometry and Stereoscopic Vision
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : July 11,  2000      
File        : a9983387

Award Number: 9983387
Award Instr.: Standard Grant                               
Prgm Manager: Guy Van Orden                           
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : July 1,  2000       
Expires     : June 30,  2003       (Estimated)
Expected
Total Amt.  : $329455             (Estimated)
Investigator: Martin Banks marty@john.berkeley.edu  (Principal Investigator current)
Sponsor     : U of Cal Berkeley
	      
	      Berkeley, CA  94720    415/642-6000

NSF Program : 7252      PERCEPTION, ACTION & COGNITION
Fld Applictn: 0116000   Human Subjects                          
Program Ref : 0000,OTHR,
Abstract    :
              PI: Banks, Martin

The proposed research will investigate the means by which
              we see 3-dimensionally via binocular vision. The research will focus on two
              issues: 1) how the human visual system solves the "matching problem" in
              binocular vision and 2) how the visual system represents surface shape and
              orientation from binocular depth cues.

The matching problem in binocular
              vision has been actively researched for decades. We still do not fully
              understand how the problem is solved. The matching problem is simply stated in
              the following way: For every image point in the left eye, the visual system
              must find the appropriate point in the other eye to match with it. With N
              possible points, the number of theoretically possible matches is N4 so with
              large N the matching process can become computationally unmanageable. The
              visual system can massively reduce the number of possible matches by using what
              is termed the epipolar constraint. For an image point in one eye, its match
              must lie on the corresponding epipolar line in the other eye. By using the
              epipolar constraint, the matching problem can be reduced to a one-dimensional
              search. However, when the eyes' positions change (e.g., fixating from far to
              near), the positions and orientations of corresponding epipolar lines change on
              the retina. Thus, to implement the epipolar constraint, the visual system must
              take the eyes' positions into account. We have developed an experimental
              procedure that will allow us to determine whether the visual system uses the
              epipolar constraint and, if so, what signals the system uses in order to
              calculate how epipolar lines ought to move when the eyes move.

We will also
              examine the means by which surface shape is represented in the visual system.
              An important cue to surface shape is the pattern of horizontal disparities
              arriving at the two eyes, but those disparities by themselves cannot yield a
              veridical estimate of shape. Other signals such as vertical disparities or
              eye-position signals must be used as well. We have shown in the previous grant
              period that changes in the eyes' vergence can cause a compelling change in
              perceived shape even when the retinal disparities are completely constant. We
              also know that prolonged viewing of a curved surface causes a subsequently
              viewed flat surface to appear curved in the opposite direction. Aftereffects
              like this have been called "disparity aftereffects" because the explanations
              offered refer to disparity encoding alone. In the proposed research, we will
              examine the curvature aftereffect. By manipulating eye-position signals and
              retinal disparities independently, we can determine whether the aftereffect is
              caused by adaptation among disparity-encoding mechanisms (which is the
              prevailing theory) or whether it is caused by adaptation in higher-level,
              shape-encoding mechanisms. Preliminary measurements suggest that the latter
              hypothesis is a better predictor of the data. We will also determine how the
              various signals involved (e.g., eye-muscle signals and vertical disparities)
              are weighted under different viewing conditions.

The proposed work will
              yield a better understanding of these aspects of binocular vision and,
              consequently, may yield insights into improvements in visual aids such as
              binocular microscopes, head- and helmet-mounted displays, and other realistic
              displays.

