Title       : Modeling by Manipulation
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : May 14,  2002       
File        : a9988575

Award Number: 9988575
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : July 1,  2000       
Expires     : June 30,  2003       (Estimated)
Expected
Total Amt.  : $450000             (Estimated)
Investigator: Pierre E. Dupont pierre@bu.edu  (Principal Investigator current)
              Robert D. Howe  (Co-Principal Investigator current)
Sponsor     : Boston University
	      881 Commonwealth Avenue
	      Boston, MA  021182394    617/353-2000

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              In this project, perceptual systems will be developed for modeling objects as
              they are manipulated during teleoperation. These systems will estimate those
              object properties that mediate the interaction between the robot and its
              environment, including object geometry, mass, moment of inertia, and friction.
              The inputs to the system will be sensor data streams from the remote
              environment, including force, position, and video signals, and the outputs will
              be models of the manipulated objects and their properties. This approach,
              modeling by manipulation, will create new robot perceptual capabilities in
              unstructured environments. In doing so, it will address a fundamental challenge
              in the development of autonomous robots: the ability to sense and model the
              environment. The proposed system will be built in the context of teleoperation
              to take advantage of the human operator's motor skills to execute the
              manipulation tasks. The sensory information returned from the remote robot will
              provide a comprehensive description of the task. By focusing the project's
              theoretical developments on specific test beds, tasks and properties, the
              essential perceptual capabilities will be developed to enable new progress on
              the other components of autonomy, including planning and control.



