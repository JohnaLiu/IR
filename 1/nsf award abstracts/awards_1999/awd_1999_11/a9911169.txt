Title       : Learning Sequences in Dynamic Decision Tasks: Focusing and Starting Small
Type        : Award
NSF Org     : SES 
Latest
Amendment
Date        : January 23,  2003   
File        : a9911169

Award Number: 9911169
Award Instr.: Standard Grant                               
Prgm Manager: Robert E. O'Connor                      
	      SES  DIVN OF SOCIAL AND ECONOMIC SCIENCES    
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : February 15,  2000  
Expires     : January 31,  2004    (Estimated)
Expected
Total Amt.  : $110213             (Estimated)
Investigator: Faison Gibson fpgibson@umich.edu  (Principal Investigator current)
Sponsor     : University of Michigan
	      3003 S State St. RM 1062
	      Ann Arbor, MI  481091274    734/764-1817

NSF Program : 1321      DECISION RISK & MANAGEMENT SCI
Fld Applictn: 0116000   Human Subjects                          
Program Ref : 0000,OTHR,
Abstract    :
              9911169
Gibson, Faison
Learning Sequences in Dynamic Decision Tasks: Focusing
              and Starting Small

In many fast-paced, repeated decisions, interpreting the
              sequence of events up to a given decision point is important for making good
              decisions. For instance, the order in which a person receives offers in an
              interactive bargaining session (e.g., a credit collector negotiating a deal
              with a debtor) often influences whether a given offer will be accepted or
              rejected. Starting offers too high or too low, or adding and subtracting
              conditions at different points in the process, can all influence the
outcome.
              It is important for the person making the offers to understand this sequential
              structure. A grasp of the relevant sequential structure is similarly important
              for making good decisions in fast-paced tasks like air traffic control, police
              dispatch, and firefighting as well as commodity and financial markets. Evidence
              from experimental dynamic decision environments indicates that decision makers
              are at best slow in developing this ability. This research extends two
              learning
models, stimulus-response (S-R) and simple recurrent neural networks
              (SRN), to derive competing recommendations for improving decision makers'
              learning under such dynamic conditions. These recommendations permit the
              predictions of the two models to be distinguished, a difficulty in past
              post-hoc analyses. The performance of the two simulation models will be
              compared experimentally with that of human subjects. The first experiment tests
              the S-R model's recommendation to focus
the options considered. Under the SRN
              model's assumptions, this recommendation actually increases the amount of
              information that must be processed for each decision, thereby hurting learning.
              The second experiment contrasts the S-R model's recommendation to focus on only
              the relevant sequences with the SRN model's recommendation to start training
              small with short sequences, not always the most relevant, first. Results will
              increase our understanding of which
recommendations improve learning most, as
              well as of how to model dynamic decision making
              appropriately.



















