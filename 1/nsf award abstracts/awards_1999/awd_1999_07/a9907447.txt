Title       : Statistical Models for Monitoring Educational Progress
Type        : Award
NSF Org     : SES 
Latest
Amendment
Date        : September 7,  1999  
File        : a9907447

Award Number: 9907447
Award Instr.: Fellowship                                   
Prgm Manager: Cheryl L. Eavey                         
	      SES  DIVN OF SOCIAL AND ECONOMIC SCIENCES    
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : September 1,  1999  
Expires     : August 31,  2000     (Estimated)
Expected
Total Amt.  : $64870              (Estimated)
Investigator: Brian W. Junker brian@stat.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 1333      METHOD, MEASURE & STATS
Fld Applictn: 
Program Ref : 0000,OTHR,
Abstract    :
              This award supports the investigator's work at the University of Pittsburgh's
              Learning Research and Development Center (LRDC).  Projects to be initiated
              include: (1) Analyzing school district data archives with an eye toward
              evaluating educational progress and monitoring the outcomes of educational
              innovations; (2) Exploring social judgement in education, in particular in the
              development of an institutional portfolio rating system for classrooms and
              schools, based on the "Principles for Learning" of LRDC's Institute for
              Learning; and (3) Laying technical groundwork for a bank of linked topical
              tests instantiating a purely standards-referenced testing program.  All three
              are connected to ongoing research programs at LRDC.  These projects are
              designed to contribute to the development of data collection systems for
              adequate school accountability systems and for educational policy evaluation. 
              Research conducted through the Institute for Learning and elsewhere suggests
              that sustained improvement in student achievement is most reliably attained
              through institutional change.  Yet most currently implemented accountability
              systems focus instead on individual student outcomes, and often are confounded
              with high-stakes decisions for individual students.  The first project will
              explore whether existing school district data archives can be exploited to
              limit additional individual student testing when student achievement data is
              called for.  The second project will apply methodology developed over the past
              ten years for student portfolio assessment to the development and rating of
              institutional portfolios intended to show that local institutions (e.g.,
              classrooms, schools and districts) are engaged in a process of professional
              development that ensures long term gains for students.  The banked tests in the
              third project would each cover fairly narrow topics, such as integer
              arithmetic, fractions, etc., and could be used for example to assess the
              distribution of student achievement within a district, school, or classroom
              relative to specific learning standards.  This research is supported by the
              Methodology,  Measurement, and Statistics Program and the Statistics and
              Probability Program under the Mid-Career Methodological Opportunities
              Fellowship Announcement.
