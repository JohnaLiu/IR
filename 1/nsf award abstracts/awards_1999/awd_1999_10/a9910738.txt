Title       : SGER: ASL Synthesizer
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : September 2,  1999  
File        : a9910738

Award Number: 9910738
Award Instr.: Standard Grant                               
Prgm Manager: Ephraim P. Glinert                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 15,  1999 
Expires     : December 31,  2000   (Estimated)
Expected
Total Amt.  : $99998              (Estimated)
Investigator: John W. Etchemendy jetch@csli.stanford.edu  (Principal Investigator current)
Sponsor     : Stanford University
	      651 Serra Street
	      Stanford, CA  94305    650/723-2300

NSF Program : 6846      UNIVERSAL ACCESS
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,9237,HPCC,
Abstract    :
              The goal of this exploratory research is to show that high quality American Sign
              Language (ASL) can be generated on a notebook or hand-held computer to support
              interaction between a deaf person and a speech-driven computer interface.   The
              ASL Synthesizer the PI would like to create would accept text that is spoken or
              typed by a person, or text that is produced by a computer, and generate
              graphical representations in the ASL alphabet.   It would also be able to
              display, upon user request via shorthand input, certain predefined ASL
              messages.   In preparation for this project, the PI's team has worked with
              several deaf colleagues and ASL interpreters during the past year to evaluate
              current research on machine-generated ASL.  They have considered the problems
              of converting ASL to printed or spoken language, and believe they have
              developed an approach based on extensions to the Dance Event Language developed
              by John Simmons at George Mason University which will provide a basis for
              eventually developing real-time two-way communication between deaf and hearing
              individuals.   Recognizing that their goal of providing on-the-fly translations
              to and from ASL is an ambitious one, the PI's team believes that at least three
              phases of research are necessary:   (1) Develop a practical method for
              generating lifelike graphical representations of the ASL alphabet and
              predefined ASL messages;   (2) Work with others in the field to develop a
              practical method for translating between English text and ASL;   (3) Develop a
              practical method for reading ASL into a computer.  The focus of the current
              project is limited to Phase 1 only.   If successful, this work will form the
              basis for future proposals to NSF to research machine translation and machine
              recognition of ASL along the lines suggested above for  Phases 2 and 3.   Under
              this award, the PI will be assisted by Neil Scott, chief engineer for the
              Archimedes Project, who will be responsible for overall technical design and
              implementation.  The research team will also include one or more members who
              are deaf.
