Title       : Flexible and Adaptive Statistical Modeling
Type        : Award
NSF Org     : DMS 
Latest
Amendment
Date        : May 22,  2002       
File        : a9971405

Award Number: 9971405
Award Instr.: Continuing grant                             
Prgm Manager: Marianthi Markatou                      
	      DMS  DIVISION OF MATHEMATICAL SCIENCES       
	      MPS  DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN
Start Date  : August 1,  1999     
Expires     : July 31,  2004       (Estimated)
Expected
Total Amt.  : $497285             (Estimated)
Investigator: Robert Tibshirani tibs@stat.stanford.edu  (Principal Investigator current)
Sponsor     : Stanford University
	      651 Serra Street
	      Stanford, CA  94305    650/723-2300

NSF Program : 1269      STATISTICS
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 0000,9179,9216,9217,HPCC,OTHR,SMET,
Abstract    :
              9971405

During the 1980's, researchers who were trying to model learning in
              the brain developed several novel learning algorithms for multilayer non-linear
              neural networks.  Somewhat incidentally, these algorithms turn out to be very
              powerful techniques for adaptive regression and classification, and have proven
              their usefulness independent of whether or not they are a good model for the
              brain.  They are now being applied to medical diagnosis, chemical process
              control, shape recognition and a wide range of other important practical
              problems.  At the same time, there have been significant advances in adaptive
              techniques in the field of statistics.  The new statistical methods are more
              powerful than classical techniques such as linear regression and linear
              discriminant analysis.  Some of the recently developed procedures include CART
              (Classification And Regression Trees), generalized additive models, MARS
              (Multivariate Additive Regression Splines), and sophisticated versions of
              nearest neighbor algorithms that learn an appropriate metric for the input
              space.  Although they come from different fields using different terminologies,
              these methods have much in common.  One item in this proposal is a research
              monograph that seeks to bring many of these ideas under one umbrella,
              explaining them in a unified fashion.  Two other items explore some recent new
              methods for improving classifiers and for adaptive model selection.


This
              work aims at developing new models and methods for making predictions based on
              historical data.  These techniques are important in many different fields
              including medical diagnosis, financial forecasting and industrial process
              control.  The area of biotechnology is an especially important application for
              these methods.  Scientists now have techniques for measuring gene expression
              levels for thousands of genes at the same time, allowing the exciting
              possibility of determining which human genes are involved in a diseases such as
              cancer and heart disease.  Sorting through the mass of information is like
              trying to find a needle in a haystack, and predictive methods like the ones
              studied here will provide an important tool in this search.


