Title       : Essential Tools for Computational Research on Visual-Gestural Language
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : March 28,  2002     
File        : a9912573

Award Number: 9912573
Award Instr.: Continuing grant                             
Prgm Manager: Ephraim P. Glinert                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : May 15,  2000       
Expires     : April 30,  2004      (Estimated)
Expected
Total Amt.  : $682602             (Estimated)
Investigator: Carol J. Neidle carol@bu.edu  (Principal Investigator current)
              Stan Sclaroff  (Co-Principal Investigator current)
              Dawn M. MacLaughlin  (Co-Principal Investigator current)
Sponsor     : Boston University
	      881 Commonwealth Avenue
	      Boston, MA  021182394    617/353-2000

NSF Program : 6846      UNIVERSAL ACCESS
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              This is the first-year funding of a three year continuing award.    Research on
              recognition and generation of signed languages and the gestural component of
              spoken languages has been held back by the unavailability of large-scale
              linguistically annotated corpora of the kind that led to significant advances
              in the area of spoken language.   A major obstacle to the production of such
              corpora has been the lack of computational tools to assist in efficient
              analysis and transcription of visual language data.      In this project the PI
              and her team will develop the tools and techniques necessary to support
              efficient transcription of finely detailed phonological information and its
              integration with information provided by computational algorithms, so as to
              enable the creation of large-scale corpora annotated at the level of
              granularity essential for computer science research.    Machine vision-based
              algorithms for semi-automation of several aspects of the transcription process
              will also be developed.

This research will result in the production and
              public dissemination of corpora that will include fine-grained linguistic
              annotations of ASL video data.  The availability of these corpora and the
              refinement of computational tools for analyzing visual data will be invaluable
              for the linguistic study of signed languages and the gestural component of
              spoken languages.    The corpora will be used in training computer models,
              thereby leading to advances in both recognition and generation of signed
              languages and gesture.   The tools will have educational applications for the
              teaching of ASL and other signed languages.  Ultimately, this research will
              have implications for human-computer interfaces, enabling users to interact
              with computers via sign language or via a combination of speech and gesture,
              and may also lead to alternate input mechanisms for disabled users as well as
              techniques for automatic recognition and classification of human actions.

