Title       : Music Plus One: A System for Synthetic Musical Accompaniment
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : August 16,  2001    
File        : a9987898

Award Number: 9987898
Award Instr.: Continuing grant                             
Prgm Manager: Mary P. Harper                          
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 1,  2000     
Expires     : January 31,  2003    (Estimated)
Expected
Total Amt.  : $176305             (Estimated)
Investigator: Christopher S. Raphael raphael@math.umass.edu  (Principal Investigator current)
Sponsor     : U of Massachusetts Amherst
	      408 Goodell Building
	      Amherst, MA  010033285    413/545-0698

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              This research focuses on creating a computer system that serves as musical
              accompanist in non-improvised music for soloist and accompaniment.  The system
              will "hear" the soloist by performing a real-time analysis of the acoustic
              signal to determine when important musical events take place.  As the piece of
              music is rehearsed, the system will train a probabilistic model of the
              soloist's rhythmic interpretation;   it will understand both what it "knows"
              and what it "doesn't know" about the soloist's interpretation by modeling both
              mean behavior and covariance structure.   The predictive power of this model
              will be combined with the real-time signal analysis to enable the  system both
              to follow and to anticipate the soloist.   In addition, the system will be
              presented with expressively played examples of the accompaniment and will train
              and utilize a model of the accompaniment's musical interpretation based on
              these.  The goal is to create a system that demonstrates both the technique and
              musicality necessary to achieve a high level of music-making.   From a modeling
              point of view, the primary challenge is one of knowledge fusion.  The system is
              faced with a number of disparate sources of knowledge including the musical
              score, the real-time analysis of the soloist's acoustic signal, training data
              from the past rehearsals, and inherent musical  constraints on the
              accompaniment.  A probabilistic model, a Bayesian Belief Network (BBN), will be
              developed that incorporates and balances these knowledge sources in a way that
              is musically believable,  automatically trainable, and computationally
              efficient.   The resulting system will be an invaluable teaching tool, as well
              as an aid to musicians preparing for performance.   The approach should be
              applicable to other domains as well.  Finally, if such an accompaniment system
              passes the musical equivalent of the "Turing Test" it would comprise a new and
              unexpected data point to be considered in our evolving understanding of the
              bounds of human and artificial intelligence.
