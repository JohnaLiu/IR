Title       : Computational Vision in Bad Weather
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 1,  2002       
File        : a9987979

Award Number: 9987979
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : July 1,  2000       
Expires     : June 30,  2003       (Estimated)
Expected
Total Amt.  : $335685             (Estimated)
Investigator: Shree K. Nayar nayar@cs.columbia.edu  (Principal Investigator current)
Sponsor     : Columbia University
	      1210 Amsterdam Avenue; MC 2205
	      New York, NY  10027    212/854-6851

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              Computational vision has made significant strides in the development of sensors
              and algorithms that recover scene properties from images. However, virtually
              all work in vision is based on the assumption that the observer is immersed in
              a transparent medium (air)and that the objects of interest are opaque. It is
              assumed that light rays reflected by the objects travel to the observer without
              attenuation or alteration. Therefore, existing vision sensors and algorithms
              have been created only to deal with clear weather. In practice, however, a
              vision system must reckon with the entire spectrum of atmospheric conditions
              commonly known as bad weather. It must continue to perform in the presence of a
              variety of conditions,including, haze, fog, rain, hail and snow.

This
              proposal outlines a comprehensive research program geared towards the
              development of models and methods that can aid vision in bad weather.  The
              first step is to understand the visual manifestations of different types of
              weather conditions.  For this, we will draw on what is already known about the
              optics of the atmosphere.  Since the atmosphere modulates the information
              carried from a scene point to the observer, it can be viewed as a mechanism of
              visual information coding. We propose the development of a general
              computational framework that exploits the brightness and color changes that are
              induced by bad weather.  Based on this framework, we will develop models and
              methods for recovering pertinent scene properties such as true (clear weather)
              color and three-dimensional structure, from images taken under different
              (unknown) weather conditions.  Such models and methods have obvious
              applications in scene understanding, autonomous navigation and video
              surveillance.  In addition, we wish to create an extensive image/video database
              that captures the wide range of visual effects caused by weather. We believe
              that such a database will make it easier for researchers to study this
              important area of computational vision.




