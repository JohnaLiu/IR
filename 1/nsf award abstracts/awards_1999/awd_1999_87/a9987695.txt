Title       : Modern Statistical Techniques For Computer Vision
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : May 15,  2002       
File        : a9987695

Award Number: 9987695
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : June 1,  2000       
Expires     : May 31,  2003        (Estimated)
Expected
Total Amt.  : $379514             (Estimated)
Investigator: Peter Meer meer@caip.rutgers.edu  (Principal Investigator current)
              David E. Tyler  (Co-Principal Investigator current)
Sponsor     : Rutgers Univ New Brunswick
	      ASB III, 3 Rutgers Plaza
	      New Brunswick, NJ  08901    732/932-0150

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              The power of modern statistical techniques is exploited to develop novel
              approaches to fundamental problems in image understanding. The common
              statistical foundation for a broad class of vision tasks is identified first,
              and then  the underlying key problems  are solved in a rigorous framework. For
              example, since heteroscedasticity inherently appears in most 3D vision tasks
              the development of a complete estimation procedure (which includes imposing
              further geometric constraints on the parameter estimates) is of great
              importance for computer vision. Such a procedure can provide a faster and more
              reliable alternative to the widely used (and too general) nonlinear
              Levenberg-Marquardt method. The task of deriving the 3D description of a scene
              (static or dynamic)  from an image sequence captured with an uncalibrated
              camera was chosen as a testbed. Estimation problems related to
              self-calibration, object recognition supported by uncertainty information, will
              not only allow us to enhance our existing toolbox but also to gain expertise in
              integrating these tools in a closed-loop autonomous vision system.


