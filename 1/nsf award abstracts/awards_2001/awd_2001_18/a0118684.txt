Title       : The Interplay Between Segmental Timing and Coarticulation: Acoustic, Perceptual,
               and Phonological Investigations
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : June 4,  2002       
File        : a0118684

Award Number: 0118684
Award Instr.: Continuing grant                             
Prgm Manager: Cecile McKee                            
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : September 1,  2001  
Expires     : August 31,  2004     (Estimated)
Expected
Total Amt.  : $202591             (Estimated)
Investigator: Patrice S. Beddor beddor@umich.edu  (Principal Investigator current)
Sponsor     : University of Michigan
	      3003 S State St. RM 1062
	      Ann Arbor, MI  481091274    734/764-1817

NSF Program : 1311      LINGUISTICS
Fld Applictn: 0116000   Human Subjects                          
Program Ref : 0000,OTHR,
Abstract    :
              ABSTRACT
Beddor 0118684

With National Science Foundation support, Dr.
              Patrice Beddor will conduct three years of linguistic research on the
              variability of speech sounds. This project investigates how a particular kind
              of variability can eventually become a systematic property of a language,
              leading to language change. The focus is the overlapping articulation of
              adjacent or nearby sounds known as "coarticulation". In some sound changes, the
              sound that triggered the coarticulation is lost over time, leaving behind only
              its coarticulatory effects. For example, in French, Hindi, and hundreds of
              other languages, coarticulatory nasality in vowels was originally triggered
              only by a following nasal consonant, such as "m" or "n". But the nasal
              consonant dropped out over time, leaving vowel nasality as a systematic and now
              required property of the word. Dr. Beddor hypothesizes that the loss of a
              coarticulatory trigger and the linking of its properties to another sound
              involve a stage in which shortened duration of the trigger is offset by more
              extensive coarticulatory influences (e.g., nasal consonants shorten as nearby
              vowels become more nasal). She further hypothesizes that listeners facilitate
              these changes by being perceptually insensitive to variation in such timing
              relationships. Dr. Beddor's research mimics the stages of a language's change
              by studying four languages that differ in the relevant timing patterns:
              English, Thai, Greek, and Ikalanga. Acoustic analyses of these languages will
              be conducted to verify the timing patterns that emerged in preliminary studies.
              These analyses will be followed by perceptual testing and further phonological
              investigations.

This multi-language research has theoretical and practical
              significance across domains affected by speech science. First, it will broaden
              the empirical database on which theories of sound change, speech production,
              and speech perception are grounded. Second, better understanding of speech
              variation and speech sound change reveals how some dialect differences emerge.
              Better understanding of dialect emergence may reduce the social stigmatization
              attached to some speech varieties. Third, the perceptual tests that explore
              listener sensitivity to speech variation have implications for theories of how
              infants extract phonetic regularities in the languages they are learning.
              Finally, these results will bear on speech technology. Computer speech
              recognition systems make more errors than humans do. This is partly because
              computer recognizers display greater sensitivity to coarticulatory variation.
              Study of the kinds of speech variability that human listeners are sensitive to
              may help solve this practical challenge in speech engineering. 

