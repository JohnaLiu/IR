Title       : NSF-CONACyT: Binational Collaborative Development of Spoken Language Technology
               in Latin American Spanish
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : September 18,  2001 
File        : a0116545

Award Number: 0116545
Award Instr.: Standard Grant                               
Prgm Manager: Mary P. Harper                          
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : October 1,  2001    
Expires     : September 30,  2003  (Estimated)
Expected
Total Amt.  : $93570              (Estimated)
Investigator: Richard M. Stern rms@cs.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9218,HPCC,
Abstract    :
              


CONACyT: Binational Collaborative Development of Spoken
              Language
Technology in Latin American Spanish




This is a standard
              award. As the use of handheld computing devices becomes more widespread it will
              be increasingly necessary for these devices to support speech input and output
              that can maintain robust performance under all conditions.   In this project
              the CMU Robust Speech Group will develop a series of complementary algorithms
              that will substantially improve the accuracy of automatic speech recognition
              systems in the presence of difficult acoustical environments including high
              levels of noise, sources of interference with time-varying characteristics
              (such as competing speech sources and background music), and a variety of
              transient noise sources encountered in office, highway, and industrial
              settings.  The research includes three complementary components: the
              development of "synergistic" sets of features that when used in combination
              will provide better recognition accuracy than can be obtained by any single
              feature set in isolation; development of a series of new procedures that
              produce the best combination of information from multiple parallel recognizers;
              and development of improved methods to achieve robust speech recognition by the
              explicit identification and reconstruction of features in time-frequency
              displays of speech that are "missing" by virtue of being damaged by noise or
              other types of interference.  The PI will transfer the technology developed in
              the course of this project to industry and to the general public by releasing
              the code of successful algorithms in Open Source form.


