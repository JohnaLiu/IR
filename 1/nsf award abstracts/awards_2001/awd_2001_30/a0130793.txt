Title       : Collaborative Research: Processing of Temporally-Coded Auditory Representations
               for Sound Separation and Localization
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : November 20,  2002  
File        : a0130793

Award Number: 0130793
Award Instr.: Continuing grant                             
Prgm Manager: Mitra Basu                              
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : January 15,  2002   
Expires     : December 31,  2003   (Estimated)
Expected
Total Amt.  : $156945             (Estimated)
Investigator: Ramdas Kumaresan kumar@ele.uri.edu  (Principal Investigator current)
Sponsor     : U of Rhode Island
	      
	      Kingston, RI  02881    401/792-1000

NSF Program : 1705      BIOLOGY & INFORMATION TECHNOLO
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 9218,HPCC,
Abstract    :
              EIA-0130793 Ramdas Kumaresan University of Rhode Island Collaborative Research: 
              Processing of Temporally-Coded Auditory Representations for Sound Separation
              and Localization

The proposed work investigates the use of two
              temporally-coded representations and temporal processing strategies for the
              separation of auditory objects.  Two temporal representations and temporal
              processing strategies for the separation of auditory objects will be used.  Two
              temporal representations of input signals will be used.  These are 1)
              phase-locked spike train responses in a simulated auditory nerve array
              (Auditory Temporal Images), and 2) an auditory-inspired signal representation
              based on adaptive demodulation (Adaptive Demodulation and Real-Zero Conversion)
              that converts bandpass signals into timings of certain zero
              crossings.

Temporal coding through phase locking is a very general strategy
              for representing sensory information through the relative timings of spikes. 
              Temporal coding is found in many sensory systems:  audition (periodicity and
              frequency discrimination, localization, echolocation), mechanoception
              (flutter-vibration, localization, movement), electroception (localization), and
              vision (fly motion detection).    The unsurpassed capabilities of biological
              auditory systems to separate, analyze, and recognize multiple sounds may be due
              to the early use of temporal codes and computations, but thus far there have
              been relatively few attempts to effectively exploit these time domain
              strategies in artificial signal processing contexts.  This collaborative
              project will combine understanding of the neural substrates of auditory
              perception (Cariani) with mathematical insights and expertise in signal
              processing (Kumaresan) to develop new biologically inspired time-domain
              approaches to auditory scene analysis.

