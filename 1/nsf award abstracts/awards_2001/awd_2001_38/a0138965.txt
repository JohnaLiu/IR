Title       : Constraint-Based Visual Hand Gesture Analysis
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 29,  2002      
File        : a0138965

Award Number: 0138965
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 1,  2002     
Expires     : July 31,  2005       (Estimated)
Expected
Total Amt.  : $379846             (Estimated)
Investigator: Thomas S. Huang huang@ifp.uiuc.edu  (Principal Investigator current)
Sponsor     : U of Ill Urbana-Champaign
	      801 South Wright Street
	      Champaign, IL  61820    217/333-2186

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9216,HPCC,
Abstract    :
              Visual hand/finger tracking and analysis has many important  potential
              applications, including human-computer interaction, rehabilitation, and the
              recognition of sign languages. The major obstacle to real-time visual
              hand/finger tracking is the huge dimensionality of the configuration space. 
              E.g., using the finger joint angles to represent the posture, the number of
              degrees of freedom is about 27.  Tracking in this high- dimensional space is
              computationally impossible.  However, finger movement is highly constrained. 
              We propose to use a 3D model-based approach, where the model will include both
              posture and motion constraints.  Tracking is done by matching the image of the
              real hand and that of the predicted view of the hand from the 3D model.  The
              crux is to use the constraints to reduce the search time.  By the end of the
              proposed period, we expect to have a good constraint representation and a good
              real-time hand/finger tracking algorithm, and to have demonstrated real-time
              tracking for the application of virtual object manipulation.
