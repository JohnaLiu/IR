Title       : Correlating Heterogeneous Measurement Data to Achieve System-Level Analysis of
               Internet Traffic Trends
Type        : Award
NSF Org     : ANI 
Latest
Amendment
Date        : September 5,  2002  
File        : a0137121

Award Number: 0137121
Award Instr.: Continuing grant                             
Prgm Manager: Mari Maeda                              
	      ANI  DIV OF ADVANCED NETWOR INFRA & RESEARCH 
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 15,  2002 
Expires     : July 31,  2005       (Estimated)
Expected
Total Amt.  : $1000794            (Estimated)
Investigator: Kimberly C. Claffy kc@caida.org  (Principal Investigator current)
Sponsor     : U of Cal San Diego
	      9500 Gilman Drive, Dept. 0934
	      La Jolla, CA  920930934    858/534-0246

NSF Program : 4095      SPECIAL PROJECTS IN NET RESEAR
Fld Applictn: 0206000   Telecommunications                      
Program Ref : 9218,HPCC,
Abstract    :
                   NSF has invested heavily in high-performance Internet infrastructure and
              development of
distributed applications, resulting in burgeoning demand for
              additional capacity and services.
We propose a project that 1) takes advantage
              of existing traffic measurement instrumentation,
and 2) enhances availability
              and utility of existing and planned distributed heterogeneous
              network
measurement data repositories.
     In today's 'cooperative Internet
              anarchy', competitive providers, struggling to meet skyrocketing
needs, do not
              significantly invest in gathering or analyzing workload data on their networks.
              Rather, Internet service providers (ISPs) match rising demand by increasing
              network capacity as fast as possible; today's core backbone links are OC48 and
              will be OC192c by 2002. This 'traditional' approach of per-link excess capacity
              is typically based on brute force over-engineering (e.g., upgrade after you
              reach a certain link utilization), rather than identification or understanding
              of parameters describing how network capacity is actually utilized. Individual
              ISPs also suffer from the fact that visibility of traffic trends is usually
              limited to their local domain. In addition, there is as yet no instrumentation
              available for gathering fine-grained workload information from any link above
              OC12 bandwidth; few such links are instrumented to do so, and most of these are
              located at lightly used research sites. Larger providers have little incentive
              to invest in measurement instrumentation, much less to risk political damage by
              making any resulting data public. Exacerbating the situation is the lack of
              rigorous analysis tools to support wide-area Internet data collection, and the
              absence of baseline data against which to compare any independent results. The
              lack of identified parameters for characterizing and managing network growth in
              a cost-effective manner is a situation that shows little sign of changing
              without substantial shift in attention to this task.
     One detrimental side
              effect is that myths about Internet growth and performance abound,
and plans
              for provisioning are often made based on locally attained data generalized to
              mythical
proportions. One of the most important contributions of our proposed
              research is to provide
the ability to base predictions of Internet traffic,
              performance, and growth on real data rather
than obsolete assumptions[1]. The
              community could make better use of its collective intellectual
resources if
              they could validate ideas against a larger variety of empirical data sets
              before
investing research and development resources in further studies.
    
              This proposal takes advantage of and integrates existing NSF-sponsored
              technologies and
tools to 1) more strategically instrument the Internet to
              capture real data of interest to both traf-
fic engineers and Internet
              modelers, 2) create distributed repositories of experimentally derived
traffic
              trend parameters while enabling access to heterogeneous network measurements,
              and
3) develop meaningful and timely analysis tools and reports. The research
              and tools proposed
under this effort can lead to empirically-based
              understanding of the evolving Internet infrastructure,
yielding results that
              benefit all who depend on this increasingly critical global resource.
The
              proposed project will also assist in the development of much-needed tools for
              navigation,
analysis, and correlated visualization of massive network data
              sets. This work is critical to advancing both research and operational efforts
              regarding the evolving commercial Internet, and
has obvious relevance to
              public policy and regulatory questions concerning the organization
              and
administration of Internet infrastructure.
