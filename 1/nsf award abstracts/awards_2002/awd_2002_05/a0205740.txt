Title       : ITR: Using Virtual Environment Technology to Understand and Augment Social
               Interaction
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : August 30,  2002    
File        : a0205740

Award Number: 0205740
Award Instr.: Continuing grant                             
Prgm Manager: C. Suzanne Iacono                       
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2002  
Expires     : August 31,  2004     (Estimated)
Expected
Total Amt.  : $1051836            (Estimated)
Investigator: James J. Blascovich blascovi@psych.ucsb.edu  (Principal Investigator current)
              Jack M. Loomis  (Co-Principal Investigator current)
              Andrew C. Beall  (Co-Principal Investigator current)
              Matthew Turk  (Co-Principal Investigator current)
              Jeremy N. Bailenson  (Co-Principal Investigator current)
Sponsor     : U of Cal Santa Barbara
	      Office of Research
	      Santa Barbara, CA  93106    805/893-4188

NSF Program : 1687      ITR MEDIUM (GROUP) GRANTS
Fld Applictn: 0104000   Information Systems                     
              0116000   Human Subjects                          
Program Ref : 1655,9216,HPCC,
Abstract    :
              This project focuses on facilitating and augmenting social interaction in
              virtual environments, particularly immersive virtual environments.  Virtual
              environment technology allows individuals to freely move about digital "worlds"
              in real time observing and interacting with the environment and 
virtual
              others within it. Increased sophistication of virtual environment technology
              and digital imaging of people promises a new age for technologically mediated
              social interaction of geographically separated individuals. However, in order
              to implement such interaction virtually in 
meaningful and productive ways, an
              understanding of the parameters of people's perceptions of each other's
              non-verbal signals (e.g., facial expressions, gestures, gaze) within virtual
              environments is necessary. Such an understanding will provide a hierarchical
              taxonomy of the necessary and 
sufficient non-verbal signals that are critical
              to social interaction within virtual environments and, therefore, must be
              tracked and rendered among interactions in virtual environments. Realizing the
              objectives of the proposed project will advance scientific understanding in the
              areas of social interaction and non-verbal behavior, human participation in
              collaborative virtual environments, and technological (e.g., computer vision)
              aspects of automated tracking and rendering of human on-verbal signals.
