Title       : ITR: Modeling Synthesis and Analysis of Human-Machine Collaborative Systems
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : September 25,  2002 
File        : a0205318

Award Number: 0205318
Award Instr.: Continuing grant                             
Prgm Manager: Stephen Griffin                         
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : October 1,  2002    
Expires     : August 31,  2007     (Estimated)
Expected
Total Amt.  : $1100000            (Estimated)
Investigator: Gregory D. Hager hager@cs.jhu.edu  (Principal Investigator current)
              Russell H. Taylor  (Co-Principal Investigator current)
              Allison M. Okamura  (Co-Principal Investigator current)
              Blake Hannaford  (Co-Principal Investigator current)
Sponsor     : Johns Hopkins University
	      3400 North Charles Street
	      Baltimore, MD  212182695    301/338-8000

NSF Program : 1687      ITR MEDIUM (GROUP) GRANTS
Fld Applictn: 0104000   Information Systems                     
Program Ref : 1655,9216,HPCC,
Abstract    :
              This project models and builds systems that augment human physical capabilities
              for performing skilled tasks.  Areas of importance for human-machine physical
              collaboration include micro-manipulation such as microsurgery or microassembly,
              and remote operation (eg in outer space or under the ocean).  It is also
              important to study such techniques in areas where great dexterity is required,
              such as medical palpation.
These systems are also important for training the
              disabled and in various educational applcations.

Human-machine
              collaborations of this sort, where a person and a robot are both "holding" the
              same knife or stick, differ from traditional interfaces in their richness of
              sensory inputs and the coupled computation and external physical reality.  The
              inclusion of the human in the feedback loop makes these systems more complex
              than older robotics applications; human expectations and reactions must be
              modeled and provided for in the system.  Depending on the application, vision,
              sound,  and force-feedback may be involved; reaction times may vary; and the
              robot manipulator may be used to add stability, micro-scale capability, and/or
              safety to the system.
