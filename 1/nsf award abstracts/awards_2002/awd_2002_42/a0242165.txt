Title       : POWRE: Visual Behaviors for Robotic Motion Control
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : November 22,  2002  
File        : a0242165

Award Number: 0242165
Award Instr.: Standard Grant                               
Prgm Manager: Caroline E. Wardle                      
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 13,  2002    
Expires     : March 31,  2004      (Estimated)
Expected
Total Amt.  : $75000              (Estimated)
Investigator: Jill Crisman   (Principal Investigator current)
Sponsor     : Franklin W. Olin College
	      1735 Great Plain Avenue
	      Needham, MA  024921245    /   -

NSF Program : 2885      CISE RESEARCH INFRASTRUCTURE
Fld Applictn: 
Program Ref : 1592,9218,HPCC,
Abstract    :
              EIA-9973470
Crisman, Jill
Northeastern University

 CISE POWRE:  Visual
              Behaviors for Robotic Motion Control 

 The long term objective of the
              proposed research is to use visual behaviors to control personal robots.  The
              POWRE funding will help the PI to restart her research program, after she has
              had to take  an extended leave due to medical conditions of her children.  The
              proposed work will specifically study visual behaviors for gaze control of a
              robot head, navigation control of a mobile base, reaching control of a
              manipulator, and grasping control of a robot hand.  The objectives are to: (i)
              determine if real-world, general purpose robotics problems can be solved using
              visual behaviors, (ii) discover the features of target objects that can be
              reliably tracked and used for visual behaviors, and (iii) discover a
              fundamental set of visual behaviors necessary to perform general purpose object
              retrieval and delivery.  To meet these objectives, a general purpose mobile
              robot will be developed and used in daily navigation task.  The robot will
              interact with person who will select visual behaviors and target objects from
              video images.  A manipulator and robot hand will be used to perform experiments
              in visual behaviors for reaching and picking up objects. Better generic target
              tracking algorithms will also be developed. Finally, the idea of tracking
              multiple targets through image sequences will be investigated and integrated
              with visual behaviors.  
 
