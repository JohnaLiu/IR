Title       : CISE Research Instrumentation: Data-Driven Modeling for Real-Time Interaction
               and Animation
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : September 24,  2002 
File        : a0242482

Award Number: 0242482
Award Instr.: Standard Grant                               
Prgm Manager: Frederica Darema                        
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2000  
Expires     : January 31,  2003    (Estimated)
Expected
Total Amt.  : $48394              (Estimated)
Investigator: Jessica Hodgins jkh@cs.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 2890      CISE INSTRUMENTATION
Fld Applictn: 
Program Ref : 9216,HPCC,
Abstract    :
              9818287
Hodgins, Jessica K.
Atkeson, Christopher G.
Georgia Institute of
              Technology

CISE Research Instrumentation:  Data-Driven Modeling for
              Real-time Interaction and Animation

This research instrumentation enables
              research projects in:

- Perception of Action
- Learning from
              Demonstration
- Animating with Experimentally Determined Parameters, and
-
              Modeling Facial Expressions

To support the aforementioned projects, for the
              capture, modeling, recognition, and generation of human motion, this award
              contributes to the purchase of motion capture equipment, graphics workstations,
              and digital cameras at College of Computing in Georgia Institute of Technology.
               The equipment will be used for several projects aimed at making it easy to
              create, control, and interact with artificial humans in
              interactive
environments for training and entertainment.  The cameras and
              motion capture equipment will capture full body and facial motion of the users.
               The processing power of the graphics workstations and other
              available
multi-processors will be used to create data-driven models for
              recognition and generation of human actions ranging from full body motions such
              as a tennis swing to subtle facial expressions.  The power of this technology
              will be demonstrated by constructing interactive environments in which the
              cameras and motion capture equipment will be used for on-line recognition of
              user actions and the graphics workstation will be used to animate human figures
              in real-time, based on the models derived off-line.  The prototype applications
              will be environments where interactivity and realism are key, such as training
              environments for physical tasks and animation of highly interactive and
              responsive characters.


