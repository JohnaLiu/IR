Title       : Trainable Visual Aids for Object Detection and Identification
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : September 23,  2002 
File        : a0209289

Award Number: 0209289
Award Instr.: Continuing grant                             
Prgm Manager: Ephraim P. Glinert                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : October 1,  2002    
Expires     : August 31,  2005     (Estimated)
Expected
Total Amt.  : $867525             (Estimated)
Investigator: Gert Cauwenberghs gert@jhu.edu  (Principal Investigator current)
              Tomaso Poggio  (Co-Principal Investigator current)
              Gislin Dagnelie  (Co-Principal Investigator current)
              Alessandro Verri  (Co-Principal Investigator current)
Sponsor     : Johns Hopkins University
	      3400 North Charles Street
	      Baltimore, MD  212182695    301/338-8000

NSF Program : 6846      UNIVERSAL ACCESS
Fld Applictn: 0104000   Information Systems                     
              0116000   Human Subjects                          
Program Ref : 9218,HPCC,
Abstract    :
              This project leverages advances in statistical learning theory, machine vision,
              and massively parallel very-large-scale-integration technology to develop a
              custom-trainable, versatile, self-contained, and mobile system for visually
              impaired users.  The system will aid the user in interacting freely with other
              people and the environment, by rapidly detecting and localizing key visual
              environmental cues and rapidly recognizing and identifying familiar people and
              objects.  At the core of the system is the "Kerneltron", a massively parallel
              Support Vector "Machine" (SVM) in silicon.  The SVM hardware will be trained
              on-line by the end user to accommodate a variety of visual detection and
              recognition tasks in everyday situations through presentation of examples.  The
              recognition core will be embedded in a portable prototype visual aid,
              interfacing with a CCD camera front-end, and an audio synthesizer back-end. 
              Menu-driven keypad control will allow direct input and feedback from the user
              in training and directing the system.  The user interface will be based on
              "OpenEyes", a wearable computer vision system for the blind.  Proof of concept
              demonstration of the hardware system and evaluation of the training and test
              performance will be conducted with feedback from volunteer impaired users.


