Title       : ITR: Learning and Measuring Perceptual Similarity
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : August 7,  2002     
File        : a0219885

Award Number: 0219885
Award Instr.: Continuing grant                             
Prgm Manager: Bhavani Thuraisingham                   
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 15,  2002    
Expires     : July 31,  2004       (Estimated)
Expected
Total Amt.  : $140080             (Estimated)
Investigator: Edward Chang echang@ece.ucsb.edu  (Principal Investigator current)
Sponsor     : U of Cal Santa Barbara
	      Office of Research
	      Santa Barbara, CA  93106    805/893-4188

NSF Program : 1686      ITR SMALL GRANTS
Fld Applictn: 0104000   Information Systems                     
Program Ref : ,1655,9216,HPCC,
Abstract    :
              Image retrieval has been an active research area for many years, but
two
              fundamental problems remain largely unsolved: 1) How best to
learn users'
              subjective query concepts, and 2) How to measure perceptual
similarity with
              significant accuracy.  The first problem concerns the
completeness of
              formulating a query concept, e.g., how to formulate a
query such as
              ``animals,'' ``cathedrals,'' or ``aircraft.'' The second
problem concerns
              search accuracy, i.e., given a learned query concept,
how to find all images
              that match that concept.

To tackle these two fundamental problems and to
              ensure that our
solutions are scalable, this project has four specific
              targets.
First, we plan to develop novel active learning algorithms
              that
quickly learn users' subjective query concepts (thoughts and
              intents)
despite time and sample constraints.  Second, we will
              design
semi-automatic image annotation and annotation refinement methods
for
              assigning semantic labels to images in order to support
              multimodality
query-concept learning and information retrieval.  Third, we
              will
devise perceptual distance functions for improving accuracy of
              visual
searches.  For instance, once a query concept such as ``enemy
              vessels''
is learned, we want to find every matching object in the
              surveillance
database, not missing any.  Finally, we plan to conduct
              validation
studies} on developed learning algorithms, using experimental
              data
provided by colleagues at various institutions (including IBM
              research
centers and Fine Arts Museums of San Francisco).




