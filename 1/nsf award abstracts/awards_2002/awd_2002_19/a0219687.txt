Title       : ITR: Evaluation and Personalization of Synthetic Voices
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : August 27,  2002    
File        : a0219687

Award Number: 0219687
Award Instr.: Continuing grant                             
Prgm Manager: Karen Kukich                            
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2002  
Expires     : June 30,  2005       (Estimated)
Expected
Total Amt.  : $394312             (Estimated)
Investigator: Alan Black awb@cs.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 1686      ITR SMALL GRANTS
Fld Applictn: 0104000   Information Systems                     
              0116000   Human Subjects                          
Program Ref : 1654,9216,HPCC,
Abstract    :
              
Evaluation and Personalization of Synthetic Voices

Abstract

This project
              addresses two key issues in the generation of natural sounding spoken output by
              computer.  The first aspect provides an evaluation strategy for synthetic
              voices.  With no clear objective measure for speech synthesis quality, it is
              hard to show improvement in systems and compare techniques.  This work provides
              a detailed list of evaluation techniques for sub-parts of the synthesis process
              including: text analysis, lexical pronunciation, prosody, and phonetic quality.
               The techniques are designed to act on existing and newly developed voices in
              other languages, where measures are often harder to come by.  Appropriate human
              experimentation is used to justify the given metrics.
The second aspect of
              this work is to improve modeling of speaker-specific acoustic phonetics.  In
              unit selection synthesis techniques, matching the lexicon with the actual
              spoken form of a particular speaker can introduce significant noise in the
              selection process.  Speakers will have particular idiolects for their dialect
              and style.  Using data-driven techniques, within knowledge-based frameworks, we
              derive appropriate segmentation types for unit selection synthesis.
Results
              are released through CMU's http://festvox.org site.


