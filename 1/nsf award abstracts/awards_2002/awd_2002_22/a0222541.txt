Title       : RUI: Machine Learning of Improvisational Time Series
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : August 23,  2002    
File        : a0222541

Award Number: 0222541
Award Instr.: Standard Grant                               
Prgm Manager: William Bainbridge                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2002  
Expires     : August 31,  2005     (Estimated)
Expected
Total Amt.  : $188366             (Estimated)
Investigator: Judy A. Franklin jfranklin@cs.smith.edu  (Principal Investigator current)
Sponsor     : Smith College
	      Elm Street
	      Northampton, MA  01063    413/584-2700

NSF Program : 6856      KNOWLEDGE & COGNITIVE SYSTEMS
Fld Applictn: 0104000   Information Systems                     
Program Ref : ,9218,HPCC,
Abstract    :
              This award for research at an undergraduate institution will support the
              development and testing of methods to create recurrent reinforcement learning
              neural networks that can solve challenging problems related to time series
              generation and analysis.  There are two main attributes of improvisation that
              make it an excellent research area for machine learning.  First, it is a
              procedure in which one makes up a solution to a problem in real-time, using
              available materials and knowledge, and in response to environmental effects. 
              Second, it requires variety, modifying the solution from one time to another,
              even under the same conditions.  Yet the overall result must be cohesive from
              beginning to end.  Thus, improvisation is a significant challenge for computer
              science.

This project will extend the range of problems that can be solved,
              through a fusion of two separate methods.  The first is recurrent neural
              networks, that are nonlinear neural networks in which the outputs of parts of
              the network are fed back to provide input to some or all parts of the network. 
              They are emerging as feedback systems that can learn to model non-Markov
              processes, can learn to predict values in a time series, and can learn to
              generate actions or control signals that depend on past behavior.  The second
              method is reinforcement learning, an area of machine learning that has taken on
              an important role in computationally solving problems that are characterized by
              sparse feedback as to whether a proposed solution is correct, given a situation
              or state.  Human beings have a much greater ability than machines currently do
              to improvise in uncertain environments, and the ability to extemporize would be
              a very important asset for intelligent software systems.

In addition to
              supporting promising research, this award will encourage broader participation
              of women in science, by involving women in research and by helping to enable
              progress in computer science at a college for women.

