Title       : Point Processes and time Series: Mutual Information Analyses
Type        : Award
NSF Org     : DMS 
Latest
Amendment
Date        : March 28,  2003     
File        : a0203921

Award Number: 0203921
Award Instr.: Continuing grant                             
Prgm Manager: John Stufken                            
	      DMS  DIVISION OF MATHEMATICAL SCIENCES       
	      MPS  DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN
Start Date  : July 15,  2002      
Expires     : June 30,  2005       (Estimated)
Expected
Total Amt.  : $261000             (Estimated)
Investigator: David R. Brillinger brill@stat.berkeley.edu  (Principal Investigator current)
Sponsor     : U of Cal Berkeley
	      
	      Berkeley, CA  94720    415/642-6000

NSF Program : 1269      STATISTICS
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 0000,OTHR,
Abstract    :
              Proposal: DMS-0203921
PI: David Brillinger
Title: Point processes and time
              series: mutual information analysis

ABSTRACT
   This research concerns the
              theoretical and empirical investigation of the mutual information coefficient.
              It extends the ordinary correlation coefficient to the case of random
              processes. The processes to be studied include: point processes, time series,
              spatial-temporal processes and random networks. The mutual information
              coefficient will become a function of time or space or frequency amongst other
              quantities. The statistical properties of a variety of types of estimates,
              including kernel-based, wavelets with shrinkage, recurrence times will be
              developed. The tools of strong approximations, limit theorems, ergodic theory
              and nonparametric estimation will be employed.
   Claude Shannon introduced
              the concepts of entropy and mutual information in 1948. These have both
              revolutionized and driven the way that our technological society has developed.
              Mutual information characterizes the strength of dependence between variates
              and of scientific relationships. It is intended to develop extensions of the
              idea to random functions and random scatter. The work will be both theory and
              data driven. The work may have important payoffs for science is about laws and
              relationships.


