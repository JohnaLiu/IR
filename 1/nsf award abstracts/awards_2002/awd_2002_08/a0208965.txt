Title       : Avatar-Guided Estimation of Human Shape and Motion
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 29,  2002      
File        : a0208965

Award Number: 0208965
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 1,  2002     
Expires     : May 31,  2005        (Estimated)
Expected
Total Amt.  : $370084             (Estimated)
Investigator: Robert T. Collins rcollins@cs.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : ,9216,HPCC,
Abstract    :
              We propose a research program to develop vision algorithms that infer human form
              and action from video sequences.  The main feature of the approach is the use
              of an animated humanoid avatar to provide strong expectations on body shape and
              motion.  A temporal sequence of body silhouette images is collapsed using line
              projections into four two-dimensional patterns that can be analyzed using
              robust signal processing techniques.  To identify activities, patterns
              generated from video of a person are matched against spatio-temporal prototypes
              generated from the humanoid avatar.  A moment-based method for coarse temporal
              and spatial pattern alignment brings model and data patterns into registration,
              so that they can be compared to classify viewpoint and activity.  The resulting
              coarse alignment predicts 2D body topology and occlusion in each video frame,
              which enables a 2D nonrigid shape matching method based on thin-plate splines
              to identify and delineate body parts in each image.  The avatar data also
              predicts which body dimension measurements can be made most reliably in which
              image frames, leading to efficient and accurate recovery of 3D body shape, pose
              and motion.  We initially plan to focus on observations of human gait.  Gait
              analysis shares many of the same challenges as the general activity analysis
              problem, namely high degree of freedom articulated motion, occlusion of body
              parts from 2D viewpoints, and idiosyncratic performance by different
              individuals.  At the same time, the periodic nature of the activity simplifies
              temporal alignment of model and data sequences, and improves overall resiliance
              to noisy data.  Success in vision-based gait analysis would enable applications
              ranging from motion capture for orthopedics to computation of human biometrics
              for smart rooms and surveillance.
