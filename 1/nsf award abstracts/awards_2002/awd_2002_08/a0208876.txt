Title       : Estimating and Recognizing 3D Articulated Motion via Uncalibrated Cameras
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 29,  2002      
File        : a0208876

Award Number: 0208876
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 1,  2002     
Expires     : July 31,  2005       (Estimated)
Expected
Total Amt.  : $383416             (Estimated)
Investigator: Stan Sclaroff sclaroff@cs.bu.edu  (Principal Investigator current)
              Vladimir Pavlovic  (Co-Principal Investigator current)
Sponsor     : Boston University
	      881 Commonwealth Avenue
	      Boston, MA  021182394    617/353-2000

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : ,9216,HPCC,
Abstract    :
              The main goal of this effort is to develop new algorithms for 3D articulated
              structure and motion estimation, from one or more uncalibrated video streams. 
              Articulated motion is exhibited by jointed structures like the human body and
              hands, as well as linkages more generally.   In this project, 3D articulated
              structure and motion estimation algorithms will be developed that can
              automatically initialize themselves, estimate multiple plausible
              interpretations along with their likelihood, and provide reliable performance
              over extended sequences.  To achieve these objectives, concepts from machine
              learning, graphical models, multiple view geometry, and structure from motion
              will be employed.  The proposed research effort will focus in two main areas:
              (1) 3D articulated pose estimation given video obtained from uncalibrated
              cameras, (2) statistical learning models that capture the dynamics of
              articulated motion, to provide top-down guidance that is needed to improve the
              pose estimation and to allow motion recognition.  Effort will also be devoted
              to investigating improved features and image segmentation methods for use in
              the front-end system. The developed methods will be tested on videos depicting
              motion of the human body and the human hand, where ground truth is available
              for quantitative comparison.
