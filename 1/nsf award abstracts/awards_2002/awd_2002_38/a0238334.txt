Title       : CAREER: Social Robots and Human Social Development
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : February 27,  2003  
File        : a0238334

Award Number: 0238334
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : March 15,  2003     
Expires     : February 29,  2008   (Estimated)
Expected
Total Amt.  : $432286             (Estimated)
Investigator: Brian M. Scassellati brian.scassellati@yale.edu  (Principal Investigator current)
Sponsor     : Yale University
	      P.O. Box 208337
	      New Haven, CT  065208337    203/432-2460

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 1045,1187,9216,HPCC,
Abstract    :
              This project focuses on the development of anthropomorphic robots that interact
              with people using natural social cues.  Socially-competent robots would have
              great practical impact; users could interact with these robots in a more
              natural and effortless way, could command them through social instruction, and
              could integrate them into daily life.  This project seeks to address both the
              technical challenges involved in constructing these robots and the ways in
              which they can be used as tools to study human social development.

The
              technical challenges of building social robots are substantial.  The design and
              construction of a robot that can produce gestures and utterances which can be
              easily interpreted by a human observer is a challenging mechanical design
              problem.  A more difficult technical challenge will be to build machines that
              can recognize human social cues such as pointing gestures, direction of gaze,
              and tone of voice.  Existing research succeeds in recognizing a few of these
              cues in structured situations, requiring visual scenes that have a constant
              background or audio signals that contain only the voice of a single speaker. 
              This project proposes to build on existing work by integrating techniques from
              multiple sensory modalities and using models of human social development as a
              roadmap for constructing more complex social behaviors.  A final engineering
              challenge will be the implementation of a computational infrastructure to
              support these algorithms.  

